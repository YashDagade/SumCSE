usage: train.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                [--model_type MODEL_TYPE] [--config_name CONFIG_NAME]
                [--tokenizer_name TOKENIZER_NAME] [--cache_dir CACHE_DIR]
                [--no_use_fast_tokenizer] [--model_revision MODEL_REVISION]
                [--use_auth_token] [--temp TEMP] [--pooler_type POOLER_TYPE]
                [--hard_negative_weight HARD_NEGATIVE_WEIGHT] [--do_mlm]
                [--mlm_weight MLM_WEIGHT] [--mlp_only_train]
                [--ortho_loss_percent ORTHO_LOSS_PERCENT]
                [--ortho_margin ORTHO_MARGIN] [--dataset_name DATASET_NAME]
                [--dataset_config_name DATASET_CONFIG_NAME]
                [--overwrite_cache]
                [--validation_split_percentage VALIDATION_SPLIT_PERCENTAGE]
                [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                [--train_file TRAIN_FILE] [--max_seq_length MAX_SEQ_LENGTH]
                [--pad_to_max_length] [--mlm_probability MLM_PROBABILITY]
                --output_dir OUTPUT_DIR [--overwrite_output_dir] [--do_train]
                [--do_eval] [--do_predict]
                [--evaluation_strategy {EvaluationStrategy.NO,EvaluationStrategy.STEPS,EvaluationStrategy.EPOCH}]
                [--prediction_loss_only]
                [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]
                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]
                [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]
                [--lr_scheduler_type {SchedulerType.LINEAR,SchedulerType.COSINE,SchedulerType.COSINE_WITH_RESTARTS,SchedulerType.POLYNOMIAL,SchedulerType.CONSTANT,SchedulerType.CONSTANT_WITH_WARMUP}]
                [--warmup_steps WARMUP_STEPS] [--logging_dir LOGGING_DIR]
                [--logging_first_step] [--logging_steps LOGGING_STEPS]
                [--save_steps SAVE_STEPS]
                [--save_total_limit SAVE_TOTAL_LIMIT] [--no_cuda]
                [--seed SEED] [--fp16] [--fp16_opt_level FP16_OPT_LEVEL]
                [--fp16_backend {auto,amp,apex}] [--local_rank LOCAL_RANK]
                [--tpu_num_cores TPU_NUM_CORES] [--tpu_metrics_debug]
                [--debug] [--dataloader_drop_last] [--eval_steps EVAL_STEPS]
                [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                [--past_index PAST_INDEX] [--run_name RUN_NAME]
                [--disable_tqdm DISABLE_TQDM] [--no_remove_unused_columns]
                [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                [--load_best_model_at_end]
                [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                [--greater_is_better GREATER_IS_BETTER] [--ignore_data_skip]
                [--sharded_ddp] [--deepspeed DEEPSPEED]
                [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                [--adafactor] [--eval_transfer]
train.py: error: the following arguments are required: --output_dir
usage: simcse_to_huggingface.py [-h] [--path PATH]
simcse_to_huggingface.py: error: argument --path: expected one argument
usage: evaluation.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]
                     [--pooler {cls,cls_before_pooler,avg,avg_top2,avg_first_last}]
                     [--mode {dev,test,fasttest}]
                     [--task_set {sts,transfer,full,na}]
                     [--tasks TASKS [TASKS ...]]
evaluation.py: error: argument --model_name_or_path: expected one argument
